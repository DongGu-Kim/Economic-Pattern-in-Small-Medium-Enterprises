{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffingtonpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import Session\n",
    "import re\n",
    "from lxml.etree import HTML\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Session()\n",
    "browser.headers.update({\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'cookie': 'rxx=1ltusvg24w7.16vrm5kn&v=1; GUCS=Abw9mMO6; GUC=AQABAQFbYcxcSUIgKwSF&s=AQAAAN9a7LVo&g=W2CBmw',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_of_articles(search_url, topic, start_page, end_page):\n",
    "    prefix = \"https://www.newscientist.com/subject/technology\"\n",
    "    article_urls = []\n",
    "    for i in range(start_page, end_page+1):\n",
    "        try:\n",
    "            r = browser.get(search_url + topic + \"/page/%s\" %str(i))\n",
    "            html_doc = r.text\n",
    "            tree = HTML(html_doc)\n",
    "            urls = tree.xpath('.//h2[@class=\"entry-title\"]/a/@href')\n",
    "            article_urls.extend(map(lambda url: prefix+url, urls))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return article_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_to_text(article_url):\n",
    "    text = \"\"\n",
    "    timestamp = \"\"\n",
    "    try:\n",
    "        r = browser.get(article_url)\n",
    "        tree = HTML(r.text)\n",
    "        timestamp = tree.xpath('.//p[@class=\"published-date\"]')\n",
    "        timestamp = timestamp[0].text\n",
    "        text = '\\n'.join([''.join(p.itertext()) for p in tree.xpath('.//div[@class=\"article-content\"]/p')])\n",
    "    except AttributeError:\n",
    "            pass\n",
    "    return text, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://www.newscientist.com/subject/\"\n",
    "topic = \"technology\"\n",
    "article_urls = get_urls_of_articles(search_url, topic, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles in technology:48\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "articles_with_timestamp = []\n",
    "for article_url in article_urls:\n",
    "    try:\n",
    "        text, timestamp = article_to_text(article_url)  #get text of article from url\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        text = str(text)\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        if (len(text.split())>=60) & (len(timestamp)>0): #get text files only if it contains more than 60 words\n",
    "            articles_with_timestamp.append({\"timestamp\": timestamp, \"article_text\": text})\n",
    "            cnt = cnt + 1\n",
    "    except:\n",
    "        pass\n",
    "print(\"Number of articles in \" + topic + \":\" +str(cnt-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newscientist_tech_article.json', 'w') as f:\n",
    "    json.dump(articles_with_timestamp, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
